# üìò AI Documentation Extractor - Technical Documentation

## üìê Technical Architecture Description

### Overview

This Streamlit-based application allows users to input one or more documentation URLs, crawl those help sites, extract structured textual content, and use GPT-4 to analyze and identify modules, submodules, and detailed descriptions‚Äîall fully automated.

### Architecture Components

#### 1. UI Layer (Streamlit App)

* Accepts one or more documentation URLs.
* Displays real-time crawl and extraction status per URL.
* Shows structured module-submodule output in JSON.

#### 2. Crawler Module (`app/crawler.py`)

* Recursively crawls documentation pages starting from the base URL.
* Extracts all relevant internal links.
* Filters out irrelevant pages (e.g., contact, terms, etc.).

#### 3. Content Extractor (`app/extractor.py`)

* Parses HTML with BeautifulSoup.
* Removes headers, footers, navigation bars, scripts, and styles.
* Organizes content into a dictionary of:

  ```
  {
    Module Title (h1): [
      {
        title: Subsection Title (h2),
        content: [paragraphs, list items]
      },
      ...
    ]
  }
  ```

#### 4. Analyzer (`app/analyzer.py`)

* Loads the `.env`-based OpenAI API key.
* Sends the flattened and concatenated text to OpenAI's GPT model.
* Asks GPT to infer:

  * Modules
  * Submodules under each
  * Accurate, structured descriptions
* Handles parsing of GPT JSON output and error reporting.

#### 5. Output Layer

* Renders result as a human-readable, expandable JSON object in Streamlit UI.
* Each URL's data is processed independently and shown sequentially.

---

## üß† Notes on Approach

### Key Design Goals

* **Simplicity**: Provide a single unified text input for URLs.
* **Transparency**: Show progress per URL (crawl, extract, analyze).
* **Scalability**: Each URL is processed independently for future parallelization.
* **AI-Powered Insight**: Use OpenAI models for intelligent structure inference.

---

## üß© Assumptions

1. **Documentation Format**:

   * Pages follow semantic HTML structures using `<h1>`, `<h2>`, `<p>`, `<ul>`.
   * Important content is in `<h1>` ‚Üí `<h2>` ‚Üí `<p>/<ul>` hierarchy.

2. **Module & Submodule Inference**:

   * `h1` is treated as a **module title**.
   * `h2` within a module is a **submodule**.
   * Paragraphs and list content under `h2` describe submodules.

3. **Rate/Quota Assumptions**:

   * User has access to `gpt-4o` or `gpt-4` with sufficient token limits.
   * Token management will be handled manually by reducing context size if needed.

---

## ‚ö†Ô∏è Edge Case Handling

| Scenario                                  | Handling                                                                              |
| ----------------------------------------- | ------------------------------------------------------------------------------------- |
| **Redirects or broken links**             | Try/Except blocks during page requests with user warnings in UI.                      |          
| **Non-standard HTML structure**           | Fallback skips unsupported tags, still attempts text extraction.                      |
| **Multiple URLs with uneven load**        | URLs processed independently; errors in one don't block others.                       |
| **API Key errors or model access issues** | Displayed as GPT errors with actionable feedback (quota, access).                     |
| **Invalid or unsupported URL**            | Validation and exception handling warn the user cleanly.                              |
